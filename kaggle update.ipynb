{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    Implémentation simple de la régression logistique avec descente de gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    n = X.shape[0] # nombre de features\n",
    "    m = X.shape[1] # nombre de d'exemples\n",
    "    # Initialiser les poids\n",
    "    weights = np.zeros((n,1))\n",
    "    b=0\n",
    "    \n",
    "    cost_list = []\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(weights.T, X) + b\n",
    "        predictions = sigmoid(z)\n",
    "  \n",
    "        # Cost Function\n",
    "        epsilon = 0.0001\n",
    "        cost = -(1/m) * np.sum(Y * np.log(predictions + epsilon) + (1-Y) * np.log(1 - predictions + epsilon))\n",
    "\n",
    "        # Gradient descent\n",
    "        dW = (1/m)*np.dot(predictions-Y, X.T)\n",
    "        dB = (1/m)*np.sum(predictions - Y)\n",
    "        \n",
    "        weights = weights - learning_rate*dW.T\n",
    "        b = b - learning_rate*dB\n",
    "        \n",
    "        # Keeping track of our cost function value\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        if(i%(num_iterations/10) == 0):\n",
    "            print(\"cost after \", i, \"iteration is : \", cost)\n",
    "    print(weights)\n",
    "    print(b)\n",
    "    return weights, b, cost_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_rest_logistic_regression(X_train, Y_train, num_labels, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    Former un modèle de régression logistique OvR pour la classification multi-classes.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    list_cost_list = []\n",
    "    # Former un modèle pour chaque classe\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        \n",
    "        # Créer des étiquettes binaires pour la classe actuelle\n",
    "        print(\"Label\", i)\n",
    "        # Vous devez vous assurer que binary_labels est un vecteur ligne.\n",
    "        binary_labels = (Y_train ==i).astype(int)\n",
    "        binary_labels = binary_labels.reshape(1, X_train.shape[1])\n",
    "        # Former un modèle de régression logistique pour la classe actuelle\n",
    "        weights,b, cost_list = logistic_regression(X_train, binary_labels, num_iterations, learning_rate)\n",
    "    liste = [weights,b]\n",
    "    models.append(liste)\n",
    "    list_cost_list.append(cost_list)\n",
    "    return models, list_cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_rest(models, X):\n",
    "    \"\"\"\n",
    "    Prédire des étiquettes pour de nouvelles données en utilisant des modèles OvR.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    print(models)\n",
    "    # Calculer les scores pour chaque classe\n",
    "    for model in models:\n",
    "        z = np.dot(model[0].T, X ) + model[1]\n",
    "        class_scores = sigmoid(z)\n",
    "        scores.append(class_scores)\n",
    "\n",
    "    # Retrouver l'indice de la classe avec le score le plus élevé pour chaque échantillon\n",
    "    predicted_labels = np.argmax(scores, axis=0)\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0\n",
      "cost after  0 iteration is :  0.6929472005572793\n",
      "cost after  50 iteration is :  7.238820507007416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoze\\AppData\\Local\\Temp\\ipykernel_17240\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after  100 iteration is :  1.9714198699684335\n",
      "cost after  150 iteration is :  1.9714198699684335\n",
      "cost after  200 iteration is :  1.9714198699684335\n",
      "cost after  250 iteration is :  7.238820507007416\n",
      "cost after  300 iteration is :  1.9714198699684335\n",
      "cost after  350 iteration is :  1.9714198699684335\n",
      "cost after  400 iteration is :  7.238820507007416\n",
      "cost after  450 iteration is :  1.9714198699684335\n",
      "Label 1\n",
      "cost after  0 iteration is :  0.6929472005572793\n",
      "cost after  50 iteration is :  0.3754373970848351\n",
      "cost after  100 iteration is :  0.3754373970848351\n",
      "cost after  150 iteration is :  0.3754373970848351\n",
      "cost after  200 iteration is :  0.3754373970848351\n",
      "cost after  250 iteration is :  0.3754373970848351\n",
      "cost after  300 iteration is :  0.3754373970848351\n",
      "cost after  350 iteration is :  0.3754373970848351\n",
      "cost after  400 iteration is :  0.3754373970848351\n",
      "cost after  450 iteration is :  0.3754373970848351\n",
      "Label 2\n",
      "cost after  0 iteration is :  0.6929472005572793\n",
      "cost after  50 iteration is :  7.614357899092585\n",
      "cost after  100 iteration is :  1.5958824778832648\n",
      "cost after  150 iteration is :  1.5958824778832648\n",
      "cost after  200 iteration is :  7.614357899092585\n",
      "cost after  250 iteration is :  1.5958824778832648\n",
      "cost after  300 iteration is :  1.5958824778832648\n",
      "cost after  350 iteration is :  7.614357899092585\n",
      "cost after  400 iteration is :  1.5958824778832648\n",
      "cost after  450 iteration is :  1.5958824778832648\n",
      "[[array([[-1.68986660e+02],\n",
      "       [ 8.42627346e+01],\n",
      "       [-3.69435486e+01],\n",
      "       [ 4.16434429e+01],\n",
      "       [-5.06467644e+00],\n",
      "       [ 2.41856371e+01],\n",
      "       [ 2.25705158e+00],\n",
      "       [-1.80894482e-02],\n",
      "       [ 2.78679996e+03],\n",
      "       [ 2.77224637e+03],\n",
      "       [-2.56366132e+00],\n",
      "       [-1.14872121e+01],\n",
      "       [-1.87674786e-08],\n",
      "       [-1.84115324e+01],\n",
      "       [-1.69232618e+01],\n",
      "       [ 1.06071188e+02],\n",
      "       [-4.73979735e+02],\n",
      "       [-4.41399649e+00],\n",
      "       [ 2.75182798e+05]]), 0.013985701519213876]]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_train = train_data.drop(columns= [\"SNo\",\"Label\"], axis = 1)\n",
    "columns = [\"SNo\",\"lat\",\"lon\",\"TMQ\",\"U850\",\"V850\",\"UBOT\",\"VBOT\",\"QREFHT\",\"PS\",\"PSL\",\"T200\",\"T500\",\"PRECT\",\"TS\",\"TREFHT\",\"Z1000\",\"Z200\",\"ZBOT\",\"time\",]\n",
    "Y_train = train_data.drop(columns, axis = 1)\n",
    "X_test = test_data.drop(\"SNo\", axis = 1)\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values\n",
    "X_test = X_test.values\n",
    "X_train = X_train.T\n",
    "Y_train = Y_train.reshape(1, X_train.shape[1])\n",
    "X_test = X_test.T\n",
    "\n",
    "\n",
    "# Paramètres du modèle\n",
    "num_labels = 3  # Pour les labels 0, 1, et 2\n",
    "num_iterations = 500  # Doit être déterminé par la validation croisée\n",
    "learning_rate = 0.1  # Doit être déterminé par la validation croisée\n",
    "\n",
    "# Former le modèle OvR\n",
    "models, list_cost_list = one_vs_rest_logistic_regression(X_train, Y_train, num_labels, num_iterations, learning_rate)\n",
    "\n",
    "\n",
    "# Faire des prédictions\n",
    "predictions = predict_one_vs_rest(models, X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
